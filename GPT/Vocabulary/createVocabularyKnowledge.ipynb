{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create knowledge based on all tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all tabels: \n",
    "https://data.qa.ssb.no/pxapi2-beta/api/v2/tables/08456?lang=no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hent_data(url):\n",
    "    # Sender en GET-forespørsel til URL-en\n",
    "    respons = requests.get(url)\n",
    "\n",
    "    # Sjekker om forespørselen var vellykket\n",
    "    if respons.status_code == 200:\n",
    "        # Returnerer JSON-innholdet i responsen\n",
    "        return respons.json()\n",
    "    else:\n",
    "        # Returnerer en feilmelding hvis forespørselen mislykkes\n",
    "        return f\"Feil i forespørsel: Statuskode {respons.status_code}\"\n",
    "\n",
    "# URL til API-endepunktet\n",
    "url = \"https://data.qa.ssb.no/pxapi2-beta/api/v2/tables?pageSize=100000\"\n",
    "\n",
    "# Kaller funksjonen og skriver ut resultatet\n",
    "result = hent_data(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data\n",
    "data = result['tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your JSON string\n",
    "\n",
    "\n",
    "# Transform data\n",
    "transformed_data = []\n",
    "for item in data: \n",
    "    new_item = {\n",
    "        \"variableNames\": item[\"variableNames\"],\n",
    "        \"label\": item[\"label\"]\n",
    "    }\n",
    "    transformed_data.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vocabulary.csv'\n",
    "\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    for item in transformed_data:\n",
    "        # Split the label at the first colon\n",
    "        parts = item['label'].split(':', 1)\n",
    "        # number = parts[0].strip().lower()  # The initial number part, converted to lowercase\n",
    "        label_text = parts[1].strip().lower() if len(parts) > 1 else ''  # The rest of the label, converted to lowercase\n",
    "\n",
    "        # Split and rejoin the label text and variable names by spaces, convert to lowercase\n",
    "        # Filter out any empty strings resulting from consecutive spaces\n",
    "        label_text = ', '.join(filter(None, label_text.split()))\n",
    "        variable_names_str = ', '.join(', '.join(filter(None, name.lower().split())) for name in item['variableNames'])  # Convert to lowercase\n",
    "\n",
    "        # Create a CSV line with the number, label text, and variable names\n",
    "        csv_line = f\"{label_text}, {variable_names_str}\\n\"\n",
    "        \n",
    "        file.write(csv_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vocabulary.csv'\n",
    "\n",
    "# Step 1: Read the file and get all lines\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# A set to keep track of unique values seen so far\n",
    "seen_values = set()\n",
    "\n",
    "# Step 2: Process each line\n",
    "processed_lines = []\n",
    "for line in lines:\n",
    "    unique_values = []\n",
    "    for value in line.strip().split(','):\n",
    "        value = value.strip()  # Remove whitespace around the value\n",
    "        if value not in seen_values:\n",
    "            seen_values.add(value)\n",
    "            unique_values.append(value)\n",
    "    processed_line = ', '.join(unique_values) + '\\n'\n",
    "    processed_lines.append(processed_line)\n",
    "\n",
    "# Step 3: Write the processed lines back to the file\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    file.writelines(processed_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vocabulary.csv'  # Replace with your actual file name\n",
    "\n",
    "# Read the file content\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Remove new lines and spaces\n",
    "content = content.replace('\\n', '').replace(' ', '')\n",
    "\n",
    "# Write the processed content back to the file\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    file.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def csv_to_docx(csv_file_path, docx_file_path):\n",
    "    # Sjekker om mappen der docx-filen skal lagres eksisterer\n",
    "    docx_folder = os.path.dirname(docx_file_path)\n",
    "    if not os.path.exists(docx_folder):\n",
    "        os.makedirs(docx_folder)\n",
    "\n",
    "    # Oppretter et nytt Document-objekt\n",
    "    doc = Document()\n",
    "\n",
    "    # Åpner CSV-filen og leser innholdet\n",
    "    with open(csv_file_path, newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Legger til hver rad fra CSV i dokumentet som en ny paragraf\n",
    "            doc.add_paragraph(', '.join(row))\n",
    "\n",
    "    # Lagrer dokumentet som en .docx-fil\n",
    "    doc.save(docx_file_path)\n",
    "\n",
    "# Eksempel på bruk av funksjonen\n",
    "csv_file_path = 'vocabulary.csv'  # Sett inn riktig filsti til din CSV-fil\n",
    "docx_file_path = '../../Knowledge/tablesVocabulary.docx'  # Navn på den genererte docx-filen\n",
    "\n",
    "csv_to_docx(csv_file_path, docx_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def csv_to_txt(csv_file_path, txt_file_path):\n",
    "    # Checks if the folder where the txt file will be saved exists\n",
    "    txt_folder = os.path.dirname(txt_file_path)\n",
    "    if not os.path.exists(txt_folder):\n",
    "        os.makedirs(txt_folder)\n",
    "\n",
    "    # Opens the CSV file and reads its contents\n",
    "    with open(csv_file_path, newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        # Opens the TXT file for writing in UTF-16\n",
    "        with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "            for row in reader:\n",
    "                # Writes each row from the CSV to the text file as a new line\n",
    "                txt_file.write(', '.join(row) + '\\n')\n",
    "\n",
    "# Example usage of the function\n",
    "csv_file_path = 'vocabulary.csv'  # Replace with the correct path to your CSV file\n",
    "txt_file_path = '../../Knowledge/tablesVocabulary.txt'  # Name of the generated txt file\n",
    "\n",
    "csv_to_txt(csv_file_path, txt_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
